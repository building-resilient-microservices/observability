#random port
server.port=0
spring.application.name=kafka-producer-demo

spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.IntegerSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

management.endpoints.web.exposure.include=prometheus, metrics, health, info

# All traces will be sent to latency analysis tool, for production use < 1.0 (100%) [default=0.1]
management.tracing.enabled=true
management.tracing.sampling.probability=1.0

# For Exemplars to work we need histogram buckets
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.distribution.percentiles-histogram.method.observed=true

# The step size to use in computing windowed statistics like max. The default is 1 minute.
# To get the most out of these statistics, align the step interval to be close to your scrape interval.
management.prometheus.metrics.export.step=5s

# Commons tags are applied to all meters
management.observations.key-values.some.tag=some.value

# IMPORTANT! for apps running version lower than Spring 3.2
# traceID and spanId are predefined MDC keys - we want the logs to include them as part of log level
# logging.pattern.level=%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]

#logging.level.io.micrometer=TRACE
#logging.level.io.opentelemetry=TRACE
